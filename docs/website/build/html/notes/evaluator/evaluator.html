<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Chess Board Evaluation &#8212; Chess Bot  documentation</title>
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=4f649999" />
    <link rel="stylesheet" type="text/css" href="../../_static/alabaster.css?v=9ddc41a9" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css?v=0a3b3ea7" />
    <link rel="stylesheet" type="text/css" href="../../_static/custom.css?v=cf12ce29" />
    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js?v=b3ba4146"></script>
    <script src="../../_static/doctools.js?v=888ff710"></script>
    <script src="../../_static/sphinx_highlight.js?v=4825356b"></script>
    <script src="../../_static/design-tabs.js?v=36754332"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="References" href="../../references.html" />
    <link rel="prev" title="Model Size" href="../modelsize/modelsize.html" />
   
  <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  <div class="document">
    
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../index.html">Chess Bot</a></h1>



<p class="blurb">Machine Learning applied to chess so that I don't have to play anymore.</p>




<p>
<iframe src="https://ghbtns.com/github-btn.html?user=mzimm003&repo=Chess&type=watch&count=true&size=large&v=2"
  allowtransparency="true" frameborder="0" scrolling="0" width="200px" height="35px"></iframe>
</p>





<h3>Navigation</h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../plan/plan.html">Plan</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../data/data.html">Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../models/models.html">Models</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../notes.html">Notes</a></li>
<li class="toctree-l1"><a class="reference external" href="https://mzimm003.github.io/Chess/documentation/build/html/index.html">Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../references.html">References</a></li>
</ul>


<hr />
<ul>
    
    <li class="toctree-l1"><a href="https://mzimm003.github.io">Mark Zimmerman's Portfolio</a></li>
    
</ul>
<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../index.html">Documentation overview</a><ul>
  <li><a href="../notes.html">Notes</a><ul>
      <li>Previous: <a href="../modelsize/modelsize.html" title="previous chapter">Model Size</a></li>
      <li>Next: <a href="../../references.html" title="next chapter">References</a></li>
  </ul></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="chess-board-evaluation">
<h1>Chess Board Evaluation<a class="headerlink" href="#chess-board-evaluation" title="Permalink to this heading">¶</a></h1>
<p>The next phase of the model will take two chess boards, each passed through the
feature extractor, and from this information must determine which of the chess
boards is a winning position and which is losing. This is done by creating a
fully connected network between the outputs of the feature extractor (for both
boards) and a several layer neural network, demonstrated in the diagram below.</p>
<figure class="align-default" id="id1">
<img alt="../../_images/initialmodel.png" src="../../_images/initialmodel.png" />
<figcaption>
<p><span class="caption-number">Fig. 18 </span><span class="caption-text">Evaluator model.</span><a class="headerlink" href="#id1" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
<section id="training">
<h2>Training<a class="headerlink" href="#training" title="Permalink to this heading">¶</a></h2>
<p>All data needed to train this evaluator has already been generated for the
autoencoder, so with few tweaks, I am ready to train the evaluator. First, the
label of winning or losing position is assumed based on the result of the game.
Second, while DeepChess randomly selected boards from winning and losing subsets
of their dataset, I suspect it is sufficient to simply flip the board to gain
both the winning and losing states. Potentially, this will be cause for overfit.
However, given the intended use of the evaluator in an alpha-beta search over
potential moves to be made in a game, I expect the highly similar board state
comparison to remain relevant. Then, with a winning and losing board state, as
done for DeepChess, the evaluator assigns likelihoods to the losing and winning
category for each board, and cross entropy is used to calculate loss.</p>
<section id="hyperparameters">
<h3>Hyperparameters<a class="headerlink" href="#hyperparameters" title="Permalink to this heading">¶</a></h3>
<p>Leaning on lessons learned in the autoencoder stage, I am avoiding making the
model too deep as long as I am adhering to the simple network layer structure,
consisting only of fully connected neurons and activation functions. Then my
hyperparameter search is largely restricted to the learning rate. To gain an
idea of the model’s capabilities, especially given the qualitative view of the
feature extractor shared <a class="reference external" href="./analysis-0308-ModelSize.md">here</a>, I first use an
“Adam” based optimizer, which should handle the topology of the loss in the
parameter space well without much sensitivity to its hyperparameters. Once
proven capable, I will switch to in an attempt to gain maximal optimization. In
the same vein, I will also use a learning rate scheduler, shrinking the learning
rate as epochs go on, to fine-tune the models’ parameters as much as possible.
This of course may lead to overfit of the validation set on which I am measuring
accuracy, but since the validation set is randomly selected from the larger
dataset, I expect it will remain representative.</p>
<p><strong>Adam</strong></p>
<p>For learning rates 1e-4, 2e-5, 1.5e-5, 1e-5, 5e-6 (shown in respective order in
the figure below), as expected, results were quite similar. For the largest
rate, learning was a bit unstable, and the rest all came very close to about 96%
accuracy. This demonstrates a capable model. On its face, it seems a search
using this evaluator should be able to pick a winning position 96% of the time.
That is quite exciting.</p>
<figure class="align-default" id="id2">
<img alt="../../_images/0315-adamlearningcurves.png" src="../../_images/0315-adamlearningcurves.png" />
<figcaption>
<p><span class="caption-number">Fig. 19 </span><span class="caption-text">Adam optimizer learning curves.</span><a class="headerlink" href="#id2" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
<p><strong>SGD</strong></p>
<p>For SGD, many training runs were completed. Surprisingly, the best learning
rates were quite high, with 0.2 being a decent balance of strong, fast learning
with low chance of divergence. Further, while there was never an obvious point
of convergence where a reduced learning rate would then continue learning, a
slowly decaying learning rate did prove to enhance the model in general. This is
similar to the training process of DeepChess, though I am only training for
20-40 epochs, opposed to 1,000. As such, the decay rates I experiment with are a
bit more aggressive. Below are the results for a decay rate of .95, .9, and .75,
where each epoch these rates are multiplied against the learning rate (initially
0.2). As expected, the more aggressive rate allows the most fine-tuning of the
parameters, though all perform similarly well.</p>
<figure class="align-default" id="id3">
<img alt="../../_images/0315-sgdlearningcurves.png" src="../../_images/0315-sgdlearningcurves.png" />
<figcaption>
<p><span class="caption-number">Fig. 20 </span><span class="caption-text">SGD optimizer learning curves.</span><a class="headerlink" href="#id3" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
<p>Finally, to ensure I cross the 97% accuracy mark, I allow the best combination
of hyperparameters to run to 40 epochs. In this case, given the aggressive decay
rate, I found no change after about 30 epochs. So, I also experimented with
holding the learning rate constant after decaying for 20, 25, and 30 epochs.
This can be seen below. Unfortunately, while there is some fluctuation in
result, none crossed 97% (though 96.98% is quite close). The fluctuation is
likely due to randomness in the parameter initialization, thereby setting each
experiment up to converge on a different local maximum. Ultimately, allowing the
learning rate to decay every epoch and halting the decay the latest (30 epochs)
produced the same best result.</p>
<figure class="align-default" id="id4">
<img alt="../../_images/0315-decaylearningcurves.png" src="../../_images/0315-decaylearningcurves.png" />
<figcaption>
<p><span class="caption-number">Fig. 21 </span><span class="caption-text">0.75 learning rate decay learning curves.</span><a class="headerlink" href="#id4" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</section>
</section>
</section>


          </div>
          
        </div>
      </div>
    <div class="clearer"></div>
  </div>
    <div class="footer">
      &copy;2024, Mark Zimmerman.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 7.1.2</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.13</a>
      
      |
      <a href="../../_sources/notes/evaluator/evaluator.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>