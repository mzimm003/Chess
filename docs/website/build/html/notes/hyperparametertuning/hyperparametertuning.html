<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Hyperparameter tuning &#8212; Chess Bot  documentation</title>
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=4f649999" />
    <link rel="stylesheet" type="text/css" href="../../_static/alabaster.css?v=9ddc41a9" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css?v=0a3b3ea7" />
    <link rel="stylesheet" type="text/css" href="../../_static/custom.css?v=4a64f76e" />
    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js?v=b3ba4146"></script>
    <script src="../../_static/doctools.js?v=888ff710"></script>
    <script src="../../_static/sphinx_highlight.js?v=4825356b"></script>
    <script src="../../_static/design-tabs.js?v=36754332"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Model Size" href="../modelsize/modelsize.html" />
    <link rel="prev" title="Algorithm" href="../trainingsetup/trainingsetup.html" />
   
  <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  <div class="document">
    
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../index.html">Chess Bot</a></h1>



<p class="blurb">Machine Learning applied to chess so that I don't have to play anymore.</p>




<p>
<iframe src="https://ghbtns.com/github-btn.html?user=mzimm003&repo=Chess&type=watch&count=true&size=large&v=2"
  allowtransparency="true" frameborder="0" scrolling="0" width="200px" height="35px"></iframe>
</p>





<h3>Navigation</h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../plan/plan.html">Plan</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../data/data.html">Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../models/models.html">Models</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../notes.html">Notes</a></li>
<li class="toctree-l1"><a class="reference external" href="https://mzimm003.github.io/Chess/documentation/build/html/index.html">Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../references.html">References</a></li>
</ul>


<hr />
<ul>
    
    <li class="toctree-l1"><a href="https://mzimm003.github.io">Mark Zimmerman's Portfolio</a></li>
    
</ul>
<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../index.html">Documentation overview</a><ul>
  <li><a href="../notes.html">Notes</a><ul>
      <li>Previous: <a href="../trainingsetup/trainingsetup.html" title="previous chapter">Algorithm</a></li>
      <li>Next: <a href="../modelsize/modelsize.html" title="next chapter">Model Size</a></li>
  </ul></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="hyperparameter-tuning">
<h1>Hyperparameter tuning<a class="headerlink" href="#hyperparameter-tuning" title="Permalink to this heading">¶</a></h1>
<p>Now with reasonable training times I can consider how to create the best feature
extractor per hyperparameters. Using Adam (adaptive moment estimation)
optimization, the hyperparameters on which I will concentrate will include the
optimizer’s learning rate, along with the model’s depth and layer widths, and
the dataset’s batch size. Adam is chosen for its ability to avoid saddle points
in the loss-space, somewhat simplifying the training. Potentially other
optimizers will be explored later to further fine tune the model.</p>
<section id="batch-size-and-learning-rate">
<h2>Batch Size and Learning Rate<a class="headerlink" href="#batch-size-and-learning-rate" title="Permalink to this heading">¶</a></h2>
<p>Now with reasonable data loading times we can consider much larger batch sizes.
This should come with the advantage of more stable learning, in that each
optimization step will be considering a large sample size. From the chart just
below I can also see larger batches come with time savings, to a point.</p>
<figure class="align-default" id="id1">
<img alt="../../_images/0301-batchsizetimings.png" src="../../_images/0301-batchsizetimings.png" />
<figcaption>
<p><span class="caption-number">Fig. 10 </span><span class="caption-text">Batch size timings.</span><a class="headerlink" href="#id1" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
<p>However, with the larger batch size we also experience fewer optimization steps,
as one occurs for each batch. To that end, I also see higher loss values
(greater error) which are much further from converging in the higher batch
sizes. This is demonstrated in the charts just below, especially in the higher
layer values, i.e. a more complete model (see <a class="reference internal" href="../trainingsetup/trainingsetup.html#trainingsetup"><span class="std std-ref">Training Setup</span></a> for more detail).</p>
<figure class="align-default" id="id2">
<img alt="../../_images/0301-batchsizeloss.png" src="../../_images/0301-batchsizeloss.png" />
<figcaption>
<p><span class="caption-number">Fig. 11 </span><span class="caption-text">Batch size loss.</span><a class="headerlink" href="#id2" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
<p>To address this I can increase the learning rate, compensating for the fewer
optimization steps. This unfortunately leads to instability before ever
achieving results similar to the small batch sizes, seen here:</p>
<figure class="align-default" id="id3">
<img alt="../../_images/0301-learningrateloss.png" src="../../_images/0301-learningrateloss.png" />
<figcaption>
<p><span class="caption-number">Fig. 12 </span><span class="caption-text">Learning rate loss.</span><a class="headerlink" href="#id3" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
<p>I could potentially address this with a greater number of training epochs, but
this seems to defeat the time saving advantage the large batch size provides. I
might also use a decaying learning rate, but to keep things straight forward
and stable, the smaller batch size already seems to provide what’s necessary.
Then going forward, in comparing models I will use a batch size of 256 and a
learning rate of 0.0001.</p>
</section>
<section id="model-size">
<h2>Model Size<a class="headerlink" href="#model-size" title="Permalink to this heading">¶</a></h2>
<p>The model size controls feature extraction in that abstract features inferred
late in the model must be well-informed by simpler features early in the model.
Thinking of a shape, I cannot know a square before I know a point, a line, a
corner, an edge, etc. Then I think what’s most important to determine in the
model is whether for the chess board, are fine, intermediate, or the most
abstract details most important, or are they all equally important. To answer
this, I propose several shapes for which level widths shrink at varied rates to
emphasize the different levels of feature abstraction:</p>
<blockquote>
<div><table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Shape</p></th>
<th class="head"><p>Shrink Rates</p></th>
<th class="head"><p>Emphasis</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>[4096, 2048, 1024, 512, 256, 128]</p></td>
<td><p>2,2,2,2,2</p></td>
<td><p>Even across all levels of abstraction</p></td>
</tr>
<tr class="row-odd"><td><p>[4096, 2048, 512, 128]</p></td>
<td><p>2,4,4</p></td>
<td><p>Finer for early levels of abstraction</p></td>
</tr>
<tr class="row-even"><td><p>[4096, 1024, 256, 128]</p></td>
<td><p>4,4,2</p></td>
<td><p>Finer for later levels of abstraction</p></td>
</tr>
<tr class="row-odd"><td><p>[4096, 1024, 512, 128]</p></td>
<td><p>4,2,4</p></td>
<td><p>Finer for intermediate levels of abstraction</p></td>
</tr>
<tr class="row-even"><td><p>[4096, 1024, 128]</p></td>
<td><p>4,8</p></td>
<td><p>Finer for early levels of abstraction</p></td>
</tr>
<tr class="row-odd"><td><p>[4096, 512, 128]</p></td>
<td><p>8,4</p></td>
<td><p>Finer for later levels of abstraction</p></td>
</tr>
</tbody>
</table>
</div></blockquote>
<p>With these shapes I also hope to control the depth of the model and demonstrate
that with the right emphasis, a smaller model is sufficient and capable.</p>
</section>
</section>


          </div>
          
        </div>
      </div>
    <div class="clearer"></div>
  </div>
    <div class="footer">
      &copy;2024, Mark Zimmerman.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 7.1.2</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.13</a>
      
      |
      <a href="../../_sources/notes/hyperparametertuning/hyperparametertuning.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>