<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Model Size &#8212; Chess Bot  documentation</title>
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=4f649999" />
    <link rel="stylesheet" type="text/css" href="../../_static/alabaster.css?v=9ddc41a9" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css?v=0a3b3ea7" />
    <link rel="stylesheet" type="text/css" href="../../_static/custom.css?v=5f4f58b7" />
    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js?v=b3ba4146"></script>
    <script src="../../_static/doctools.js?v=888ff710"></script>
    <script src="../../_static/sphinx_highlight.js?v=4825356b"></script>
    <script src="../../_static/design-tabs.js?v=36754332"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Chess Board Evaluation" href="../evaluator/evaluator.html" />
    <link rel="prev" title="Hyperparameter tuning" href="../hyperparametertuning/hyperparametertuning.html" />
   
  <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  <div class="document">
    
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../index.html">Chess Bot</a></h1>



<p class="blurb">Machine Learning applied to chess so that I don't have to play anymore.</p>




<p>
<iframe src="https://ghbtns.com/github-btn.html?user=mzimm003&repo=Chess&type=watch&count=true&size=large&v=2"
  allowtransparency="true" frameborder="0" scrolling="0" width="200px" height="35px"></iframe>
</p>





<h3>Navigation</h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../plan/plan.html">Plan</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../data/data.html">Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../models/models.html">Models</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../notes.html">Notes</a></li>
<li class="toctree-l1"><a class="reference external" href="https://mzimm003.github.io/Chess/documentation/build/html/index.html">Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../references.html">References</a></li>
</ul>


<hr />
<ul>
    
    <li class="toctree-l1"><a href="https://mzimm003.github.io">Mark Zimmerman's Portfolio</a></li>
    
</ul>
<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../index.html">Documentation overview</a><ul>
  <li><a href="../notes.html">Notes</a><ul>
      <li>Previous: <a href="../hyperparametertuning/hyperparametertuning.html" title="previous chapter">Hyperparameter tuning</a></li>
      <li>Next: <a href="../evaluator/evaluator.html" title="next chapter">Chess Board Evaluation</a></li>
  </ul></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="model-size">
<h1>Model Size<a class="headerlink" href="#model-size" title="Permalink to this heading">¶</a></h1>
<p>Each of the model sizes provided previously:</p>
<blockquote>
<div><table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Shape</p></th>
<th class="head"><p>Shrink Rates</p></th>
<th class="head"><p>Emphasis</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>[4096, 2048, 1024, 512, 256, 128]</p></td>
<td><p>2,2,2,2,2</p></td>
<td><p>Even across all levels of abstraction</p></td>
</tr>
<tr class="row-odd"><td><p>[4096, 2048, 512, 128]</p></td>
<td><p>2,4,4</p></td>
<td><p>Finer for early levels of abstraction</p></td>
</tr>
<tr class="row-even"><td><p>[4096, 1024, 256, 128]</p></td>
<td><p>4,4,2</p></td>
<td><p>Finer for later levels of abstraction</p></td>
</tr>
<tr class="row-odd"><td><p>[4096, 1024, 512, 128]</p></td>
<td><p>4,2,4</p></td>
<td><p>Finer for intermediate levels of abstraction</p></td>
</tr>
<tr class="row-even"><td><p>[4096, 1024, 128]</p></td>
<td><p>4,8</p></td>
<td><p>Finer for early levels of abstraction</p></td>
</tr>
<tr class="row-odd"><td><p>[4096, 512, 128]</p></td>
<td><p>8,4</p></td>
<td><p>Finer for later levels of abstraction</p></td>
</tr>
</tbody>
</table>
</div></blockquote>
<p>have been trained over 20 epochs.</p>
<section id="all-model-learning-curves">
<h2>All Model Learning Curves<a class="headerlink" href="#all-model-learning-curves" title="Permalink to this heading">¶</a></h2>
<p>Unfortunately, the learning rate of 0.0001 ultimately proved high for the first,
largest model, in that it caused unstable learning. So, for this model I chose a
slightly smaller learning rate of 0.000025. This may disadvantage the model
compared to the others, but ultimately is of less consequence than other issues
holding back the larger models, to be discussed later.</p>
<p>The figure below considers all models, in order of the table above, with the
initial run of the large model at lr=0.0001 not pictured, and its replacement
run at lr=0.000025 at the bottom of the key. The key takeaways here are that the
smaller the model the better the performance, and that most models are not done
learning. The larger models are likely suffering simply for their complexity. It
is expected they would ultimately perform better than smaller, being capable of
creating more nuance, but may suffer from issues like a vanishing gradient
through the layers. This should be managed to some extent by the layer-by-layer
training procedure (see <a class="reference internal" href="../trainingsetup/trainingsetup.html#trainingsetup"><span class="std std-ref">Training Setup</span></a>), but
might further be improved by introducing some normalization between layers as
well.</p>
<figure class="align-default" id="id1">
<img alt="../../_images/0308-allmodels.png" src="../../_images/0308-allmodels.png" />
<figcaption>
<p><span class="caption-number">Fig. 10 </span><span class="caption-text">All model learning curves.</span><a class="headerlink" href="#id1" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</section>
<section id="learning-curves-by-size">
<h2>Learning Curves By Size<a class="headerlink" href="#learning-curves-by-size" title="Permalink to this heading">¶</a></h2>
<p>Considering the 4 layer models, I can see the most advantage is provided by
concentrating on intermediate features. This suggests wasted resource with
models overly concerned with observation relationships of the finest detail, yet
lack of ability with models which attempt to jump beyond more elemental
observation relationships.</p>
<figure class="align-default" id="id2">
<img alt="../../_images/0308-medmodels.png" src="../../_images/0308-medmodels.png" />
<figcaption>
<p><span class="caption-number">Fig. 11 </span><span class="caption-text">Medium model learning curves.</span><a class="headerlink" href="#id2" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
<p>For the smallest models, there is no option concentrating on intermediate
levels, but again we see the model attempting to jump elemental relationships
doing a bit worse. So, better to waste a bit of a resource to establish the
necessary ability.</p>
<figure class="align-default" id="id3">
<img alt="../../_images/0308-smallestmodels.png" src="../../_images/0308-smallestmodels.png" />
<figcaption>
<p><span class="caption-number">Fig. 12 </span><span class="caption-text">Smallest model learning curves.</span><a class="headerlink" href="#id3" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
<p>Since the smallest models did best from how the experiments have been conducted
thus far, for the purposes of moving forward in the project. I will rely on the
[4096, 1024, 128] model as my feature extractor. To give it the best chance I
have also continued its training to 40 epochs, which did provide slow steady
improvement as expected.</p>
<figure class="align-default" id="id4">
<img alt="../../_images/0308-bestmodel.png" src="../../_images/0308-bestmodel.png" />
<figcaption>
<p><span class="caption-number">Fig. 13 </span><span class="caption-text">Best model learning curves.</span><a class="headerlink" href="#id4" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</section>
<section id="measurement-peculiarities">
<h2>Measurement peculiarities<a class="headerlink" href="#measurement-peculiarities" title="Permalink to this heading">¶</a></h2>
<p>Also of note in the graphs above, is the superb scores in accuracy, precision,
and recall. These may be deceptive, and are best considered for relative values
between models, opposed to thinking all models are working exceptionally well.
This is due to the nature of the data being auto-encoded. The data is a 111x8x8
tensor of mostly zeros. The specifics of the data are provided by Petting Zoo
<a class="reference external" href="https://pettingzoo.farama.org/environments/classic/chess/">here</a>. In short,
each of the 111 channels mostly represent a single group of pieces, meaning on
each slice, maybe 1 or 2 out of 64 cells are set to true. So even if the model
created an empty tensor of 111x8x8 ‘false’s, accuracy would be high. Further,
some channels are there to represent player turn, or simply always be set to
true for all 64 squares. These imbalances in what’s being learned affect
accuracy, precision, and recall. In the future it may be beneficial to split the
observation being auto-encoded, and avoid making the model learn parts easily
calculated.</p>
</section>
<section id="qualitative-analysis">
<h2>Qualitative analysis<a class="headerlink" href="#qualitative-analysis" title="Permalink to this heading">¶</a></h2>
<p>Because of the issues described above, it is important to get a qualitative
sense of the models’ ability. For this I have sampled a few data points from the
training and validation sets and mapped the current board state (channels 7-18).
Below are the results of all models run, as well as a comparison between the
best model at 20 and at 40 epochs.</p>
<section id="auto-encoded-training-data">
<h3>Auto-encoded Training Data<a class="headerlink" href="#auto-encoded-training-data" title="Permalink to this heading">¶</a></h3>
<figure class="align-default" id="id5">
<img alt="../../_images/0308-allmodelstrainqual.png" src="../../_images/0308-allmodelstrainqual.png" />
<figcaption>
<p><span class="caption-number">Fig. 14 </span><span class="caption-text">All models - autoencoded training set.</span><a class="headerlink" href="#id5" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</section>
<section id="auto-encoded-validation-data">
<h3>Auto-encoded Validation Data<a class="headerlink" href="#auto-encoded-validation-data" title="Permalink to this heading">¶</a></h3>
<figure class="align-default" id="id6">
<img alt="../../_images/0308-allmodelsvalqual.png" src="../../_images/0308-allmodelsvalqual.png" />
<figcaption>
<p><span class="caption-number">Fig. 15 </span><span class="caption-text">All models - autoencoded validation set.</span><a class="headerlink" href="#id6" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</section>
<section id="auto-encoded-training-data-best-models">
<h3>Auto-encoded Training Data - Best Models<a class="headerlink" href="#auto-encoded-training-data-best-models" title="Permalink to this heading">¶</a></h3>
<figure class="align-default" id="id7">
<img alt="../../_images/0308-bestmodelstrainqual.png" src="../../_images/0308-bestmodelstrainqual.png" />
<figcaption>
<p><span class="caption-number">Fig. 16 </span><span class="caption-text">Best models - autoencoded training set.</span><a class="headerlink" href="#id7" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</section>
<section id="auto-encoded-validation-data-best-models">
<h3>Auto-encoded Validation Data - Best Models<a class="headerlink" href="#auto-encoded-validation-data-best-models" title="Permalink to this heading">¶</a></h3>
<figure class="align-default" id="id8">
<img alt="../../_images/0308-bestmodelsvalqual.png" src="../../_images/0308-bestmodelsvalqual.png" />
<figcaption>
<p><span class="caption-number">Fig. 17 </span><span class="caption-text">Best models - autoencoded validation set.</span><a class="headerlink" href="#id8" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</section>
</section>
</section>


          </div>
          
        </div>
      </div>
    <div class="clearer"></div>
  </div>
    <div class="footer">
      &copy;2024, Mark Zimmerman.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 7.1.2</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.13</a>
      
      |
      <a href="../../_sources/notes/modelsize/modelsize.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>